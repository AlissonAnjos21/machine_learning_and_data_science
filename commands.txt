 pd.read_csv((base de dados)) -> Recebe o caminho (sistema de pastas) de um arquivo csv e lê ele possibilitando, assim, a sua manipulação;

.head() -> Exibe os 5 primeiros valores da base de dados utilizada, esse número pode ser alterado ao se informar um parâmetro;

.tail() -> Exibe os 5 últimos valores da base de dados utilizada, esse número pode ser alterado ao se informar um parâmetro;

.describe() -> Exibe algumas coisas úteis, como número de respostas, médias, desvios padrão, etc;

np.unique(base de dados[coluna]) -> Recebe como parâmetro uma coluna da base de dados e retorna a as diferentes respostas presentes nas mesmas, ou seja, não repete valores iguais. Ao passar-se como parâmetro return_counts=True, ele informa a quantidade de vezes que aquele dado apareceu;

sns.countplot(x=(valor)) -> Recebe como parâmetro um valor para x e assim controi uma gráfico de barras mostrando a quantidade de cada uma das possibilidades desse valor x;

plt.show() -> Exibe o gráfico criado para o usuário através de uma interface gráfica;

plt.hist(x = base de dados[coluna]) -> Recebe um valor de x, com uma coluna da base de dados, criando com ele um gráfico de barras com intervalos;

px.scatter_matrix(base de dados, dimensions=[coluna1, coluna2, etc]) -> Recebe como parâmetros a base de dados e as colunas que serão exibidas e produz um gráfico para cada coluna com os campos tanto na direção vertical quanto na horizontal. Possui como um dos parâmetros opcionais o color, que recebe uma das colunas e, assim, exibe quais itens do gráfico correspondem aos intervalos do item da coluna informada;

.loc[base de dados[coluna] (condição se tiver)] -> Localiza os dados de alguma coluna; podendo ser também aplicado algum filtro;

.drop() -> Recebe como parâmetro o índice de um elemento que cumpre determianda condição, sendo que, os elementos que cumprirem tal condição serão apagados da base de dados;

.index -> Informa o índice de algo;

.sum -> Retorna a soma de determinada coisa. Dependendo de como utilizada, pode retornar quantas vezes algo apareceu;

.mean() -> Informa a média de algo;

.isnull() -> Informa se valores da tabela que são ou não nulos retornando True. Caso seja passado como parâmetro uma base de dados com determinada coluna, ele retorna True para os valores nulos dentro daquela coluna;

.fillna() -> Recebe um valor como parãmetro e preenche os campos com valores nulos. Para que ele consiga alterar o valor da variável da base de dados e salvar o novo valor nela, é necessário informar que o parâmetro inplace=True;

.isin -> Informa True caso o valor ao qual ele esteja acessando exista dentro de um intervalo que foi informado como parâmetro. Na maior parte das vezes usa-se uma lista contendo os valores desejados e informa-se como parâmetro;

.values -> Informa o valor de determinado item, convertendo-o para um numpy array;

.iloc -> Seleciona linhas e colunas do data frame, sendo que, o primeiro parâmetro é relativo as linhas desejadas. Já o segundo parâmetro, é referente às colunas a serem pegadas. Para selecioná-las, é necessário informar os intervalos, de forma semelhante a uma lista/tupla;

.min() -> Seleciona o menor valor de um agrupamento de valores;

.max() -> Seleciona o maior valor de um agrupamento de valores;

(objeto StandardScaler).fit_transform() -> Recebe como parâmetro uma lista de dados e os padroniza;

px.treemap(base de dados, path=[colunas]) -> Recebe a base de dados e a coluna desejada. Assim, criando uma representação retangularcom base nas respostas. Aquelas respostas que aparecem mais ficam maiores, equanto as que aparecem menos ficam proporcionalmente menores. Quando é informado mais de uma coluna, aparecem outras representações retangulares dentro da representação principal (primeira representação), esses sub-retângulos, assim como o retângulo principal, também são proporcionais ao número de ocorrencias;

px.parallel_categories(base de dados, dimensions=[coluna1, coluna2, etc]) -> Recebe como parâmetros a base de dados e as colunas que serão exibidas e gera uma representação gráfica que liga as ocorrencias (valores das colunas) uma com a outra por meio de linhas;

.columns -> Informa as colunas presentes na base de dados;

(objeto LabelEncoder).fit_transform(x[:, indice coluna]) -> Transforma um dado do tipo Categórico em um dado do tipo Numérico;

ColumnTransformer(transformers=[('OneHot', OneHotEncoder(), [lista com os índices das colunas que serão sub-divididas])], remainder='passthrough') -> Recebe uma lista com os valores dos índices que se deseja sub-dividir e os sub-divide, ou seja, para cada diferente opção de valor que uma coluna pode ter, ele cria uma sub-coluna, se o valor da linha corresponder ao da sub-coluna o valor dessa sub-coluna é 1, caso o valor da linha não corresponda ao da sub-coluna, o seu valor é 0. Só é possível ter um valor de 1 por cada linha de sub-coluna de coluna. Além disso, ao final, é necessário informar que o ramainder='passthrough', isso faz com que os índices das colunas da base de dados não selecionados continuem os mesmos. Caso contrário, essas colunas não selecionadas seriam pagadas, permecendo apenas aquelas selecionadas;

(objeto OneHotEncoder).fit_transform(x).toarray() -> Executa o processo citado anteriormente e converte o dado obtido para o formato array;

.toarray() -> Converte algo para o formato de array, tem coisas que não são capazes de serem transformadas em array;

.shape -> Retorna a quantidade de, respectivamente, linhas e colunas de uma base de dados;

(X_treinamento, X_teste, Y_treinamento, Y_teste) = train_test_split(x, y, test_size=(percentual de dados separados para o teste), random_state = (qualquer número (0 por convenção))) -> Separa dados para as variáveis de treinamento e para as variáveis de teste. O text_size é referente ao percentual de dados que você quer separar para o teste, ex: 0.25 = 25%. O random_state é para que após cada execução ele mantenha um valor padrão para os dados. Caso não fosse utilizado, a cada execução os valores seriam diferentes, por isso, é mais fácil utilizar esse atributo, principalmente em momentos de criação/teste. O número que ele recebe pode ser qualquer um, porém, por convenção, usá-se 0;

pickle.dump([variáveis], arquivo aberto) -> Possibilita salvar certas variáveis em arquivos. A partir disso, não é necessário realizar o pre-processamento de dados novamente em cada novo arquivo;

pickle.load(arquivo aberto) -> Carrega um arquivo pickle que contém os dados salvos, como mencionados no exemplo anterior;

.fit(x treinamento, y treinamento) -> Recebe a base de dados histórica para conseguir realizar os cálculos de predição;

.predict(listas contendo novos valores x) -> Recebe uma lista contendo uma ou mais listas com novos valores x. Com base nos dados históricos, ele calculará qual a chance do valor pertencer a uma das classes anteriormente informadas no método fit();

(objeto GaussianNB).classes_ -> Informa as classes existentes;

(objeto GaussianNB).class_count_ -> Informa quantas vezes cada classe aparece na base de dados;

(objeto GaussianNB).class_prior_ -> Informa a frequência em que cada classe aparece;

accuracy_score(y teste, valor obtido por predição) -> Retornará o percentual de acerto;

confusion_matrix(y_teste, valor obtido por predição) -> Retornará uma matriz, onde na primeira linha e na primeira coluna está os valores que eram e ele apontou que eram, na primeira linha e segunda coluna está os valores que não eram e ele apontou como se fossem, na segunda linha e primeira coluna estão os valores que não eram e ele apontou que eram, por fim, na segunda linha e segunda coluna estão os valores que não eram e ele apontou como se não fossem;

(objeto ConfusionMatrix).score(x teste, y teste) -> Após receber o x teste ele realiza os cálculos da técnica Naive Bayes e após isso compara com o resultado oficial, ou seja, com o y teste;

classification_report(y teste, valor obtido por predicao) -> Informa alguns dados interessantes sobre os acertos e os erros da predição;

DecisionTreeClassifier(criterion='entropy', random_state = (qualquer número)) -> Permite instanciar um objeto para que a partir deste seja criada uma árvore de decisão baseada no ganho da entropia. O random_state, como já mencionado anteriormente, é útil para que após cada execução os resultados encontrados sejam os mesmos;

(objeto DecisionTreeClassifier).feature_importances_ -> Informa a importância de cada um dos atributos com base no ganho de informação por entropia;

tree.plot_tree(objeto DecisionTreeClassifier, feature_names=(variável com uma lista contendo os atributos), class_names = (objeto DecisionTreeClassifier).classes_, filled = True) -> Informa os ramos da árvore e seus respectivos ganhos de informação com base na entropia. O Parâmetro feature_names auxilia na compreenção do atributo ao qual o galho se refere, o class_names auxilia na compreenção da classe a qual o galho se refere, e o filled = True melhora a representação gráfica da árvore obtida, colorindo-a;

RandomForestClassifier(n_estimators=(número de árvores que você quer), criterion='entropy', random_state=(qualquer número)) -> Cria um número pré-definido de árvores de decisão, cada uma dessas árvores é feita a partir de certas colunas da base de dados, essas colunas são escolhidas randomicamente, ao contrário de uma árvore comum que usa apenas uma árvore com todas as colunas da base de dados. O parâmetro n_estimators recebe o número de árvores que se deseja criar, o parâmetro criterion recebe o valor entropy para que as árvores criadas sejam baseadas no ganho de informação por entropia, já o random_state recebe um valor qualquer para que após cada execução, os valores não se alterem, sendo útil para testes;

################################################################################################################
Orange:

Orange.data.Table((caminho do arquivo csv)) -> Lê um arquivo csv;

(objeto base de dados Orange).domain -> Informa os nomes das colunas da base de dados;

(objeto CN2Learner)(base de dados Orange) -> Cria um objeto que detem as regras de decisão com base no algoritmo CN2Learner;

(objeto regras CN2Learner).rule_list -> Informa através de uma iteração a lista de regras criada pelo algoritmo CN2Learner;

(objeto regras CN2Learner)([[dados previsores treinamento]]) -> Recebe os dados previsores de treinamento e a partir das regras definidas, informa a qual classe os dados informados pertencem. O valor que ele retorna é referente ao índice que representa a sua classe;

(objeto base de dados Orange).domain.class_var.values -> Retorna uma tupla que informa as classes existentes na base de dados, cada opção de classe pode ser representada pelo índice da tupla retornada;

Orange.evaluation.testing.sample(base de dados em formato Orange, n = (percentual da base de dados que será dedicado ao teste)) -> Divide a base de dados em duas listas, a primeira lista, com índice 0, representa os dados de teste, já a segunda lista, a de índice 1, representa os dados de treinamento;

Orange.evaluation.testing.TestOnTestData(base de treinamento, base de teste, [lambda testdata: variável com as regras]) -> Realiza as predições com base nas regras estabelecidas e com base nos dados recebidos;

Orange.evaluation.CA(predições) -> Recebe as predições e informa o percentual de acerto do algoritmo;

(registro da base de dados Orange).get_class() -> Informa a qual classe pertence um determinado registro da base de dados Orange;

################################################################################################################

Counter(item) -> Retorna um dicionário onde cada chave é um dos valores que aparecem e seu valor é a quantidade de vezes que o valor aparece;

KNeighborsClassifier(n_neighbors = (número de vizinhos que você quer comparar (5 é o padrão)), metric='minkowski', p=2) -> O kNN é um algoritmo que classifica novos registros com base na proximidade que esses registros possuem se comparados com a base de treinamento. Ele recebe o número de vizinhos que se deseja abranger, a métrica minkowski e o p=2 que informa que o método utilizado para calcular a distância será baseado no cálculo euclidiano; 
